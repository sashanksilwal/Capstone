{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e98c8fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import (\n",
    "    FloatTensorType,\n",
    "    StringTensorType,\n",
    "    DoubleTensorType,\n",
    "    Int64TensorType,\n",
    ")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03665e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model(filepath):\n",
    "    return pickle.load(open(filepath, \"rb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "689eb972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_onnx_model(onnx_model, filepath):\n",
    "    with open(filepath, \"wb\") as f:\n",
    "        f.write(onnx_model.SerializeToString())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fa7ab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_onnx(sklearn_model, initial_type, seps=None):\n",
    "    options = None\n",
    "    if seps:\n",
    "        options = seps\n",
    "    return convert_sklearn(sklearn_model, \"tfidf\" if seps else None, initial_types=initial_type, options=options)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19ab98a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_classification = \"testing/classification_test.onnx\"\n",
    "file_path_clustering = \"testing/clustering_test.onnx\"\n",
    "file_path_classification_tfidf = \"testing/classification_tfidf_test.onnx\"\n",
    "file_path_clustering_tfidf = \"testing/clustering_tfidf_test.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bee77925",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the models\n",
    "classification_model = load_model(\"classification_model\")\n",
    "clustering_model = load_model(\"clustering_model\")\n",
    "classification_tfidf_model = load_model(\"classification_tfidf_model\")\n",
    "clustering_tfidf_model = load_model(\"clustering_tfidf_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "930c3ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the initial types and options for the ONNX conversion\n",
    "seps = {TfidfVectorizer: {\"separators\": [\" \"]}}\n",
    "num_features = 1\n",
    "initial_type = [(\"float_input\", StringTensorType([None, num_features]))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09fc21b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the models to ONNX and save them to files\n",
    "\n",
    "num_features = 499\n",
    "\n",
    "initial_type = [('float_input', FloatTensorType([   None, num_features]))]\n",
    "onnx_classification = convert_sklearn(classification_model,   initial_types=initial_type,   options={id(1):{'raw_scores': True, \"zipmap\": True}})\n",
    "\n",
    "save_onnx_model(onnx_classification, file_path_classification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b612462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 918\n",
    "initial_type = [('float_input', FloatTensorType([None, num_features]))]\n",
    "onnx_clustering = convert_sklearn(clustering_model, initial_types=initial_type)\n",
    "\n",
    "save_onnx_model(onnx_clustering, file_path_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a99bcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sashanksilwal/opt/anaconda3/envs/PythonGPU/lib/python3.6/site-packages/skl2onnx/common/_container.py:698: UserWarning: Unable to find operator 'Tokenizer' in domain 'com.microsoft' in ONNX, op_version is forced to 1.\n",
      "  op_type, domain))\n"
     ]
    }
   ],
   "source": [
    "seps = {TfidfVectorizer: {\"separators\": [\" \"]}}\n",
    "num_features = 1\n",
    "initial_type = [('float_input', StringTensorType([None, num_features]))]\n",
    "onx_clustering_tfidf = convert_sklearn(clustering_tfidf_model,\"tfidf\", initial_types=initial_type, options=seps)\n",
    "\n",
    "save_onnx_model(onx_clustering_tfidf, file_path_clustering_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "644696ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "seps = {TfidfVectorizer: {\"separators\": [\" \"]}}\n",
    "num_features = 1\n",
    "initial_type = [('float_input', StringTensorType([None, num_features]))]\n",
    "onx_classification_tfidf = convert_sklearn(classification_tfidf_model,\"tfidf\", initial_types=initial_type, options=seps)\n",
    "\n",
    "save_onnx_model(onx_classification_tfidf, file_path_classification_tfidf)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea56559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
