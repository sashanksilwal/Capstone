{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ee5ab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType, StringTensorType\n",
    "from skl2onnx.common.data_types import DoubleTensorType, Int64TensorType\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19810820",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model = pickle.load(open('classification_model', 'rb'))\n",
    "clustering_model = pickle.load(open('clustering_model', 'rb'))\n",
    "\n",
    "classification_tfidf_model = pickle.load(open('classification_tfidf_model', 'rb'))\n",
    "clustering_tfidf_model = pickle.load(open('clustering_tfidf_model', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94314a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    }
   ],
   "source": [
    "# checking the model type\n",
    "\n",
    "print(type(clustering_model))\n",
    "print(type(classification_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e0256f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n"
     ]
    }
   ],
   "source": [
    "# checking the model type\n",
    "\n",
    "print(type(clustering_tfidf_model))\n",
    "print(type(classification_tfidf_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b103b63f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_models():\n",
    "    print(classification_model)\n",
    "    print(clustering_model)\n",
    "    print(classification_tfidf_model)\n",
    "    print(clustering_tfidf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfdb3e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_classification = \"models/classification_test.onnx\"\n",
    "file_path_clustering = \"models/clustering_test.onnx\"\n",
    "file_path_classification_tfidf = \"models/classification_tfidf_test.onnx\"\n",
    "file_path_clustering_tfidf = \"models/clustering_tfidf_test.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31a1811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Classification Model into ONNX format\n",
    "# pipe = Pipeline([\n",
    "#     ('norm', MLPClassifier())\n",
    "# ])\n",
    "\n",
    "num_features = 499\n",
    "\n",
    "initial_type = [('float_input', FloatTensorType([   None, num_features]))]\n",
    "# onx = convert_sklearn(classification_model,   initial_types=initial_type,   options={\"zipmap\": False})\n",
    "onx = convert_sklearn(classification_model,   initial_types=initial_type,   options={id(1):{'raw_scores': True, \"zipmap\": False}})\n",
    "\n",
    "\n",
    "with open(file_path_classification, \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "510b0b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Clustering Model into ONNX format\n",
    "\n",
    "num_features = 918\n",
    "initial_type = [('float_input', FloatTensorType([None, num_features]))]\n",
    "onx = convert_sklearn(clustering_model, initial_types=initial_type)\n",
    "\n",
    "\n",
    "with open(file_path_clustering, \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f45fb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sashanksilwal/opt/anaconda3/envs/PythonGPU/lib/python3.6/site-packages/skl2onnx/common/_container.py:698: UserWarning: Unable to find operator 'Tokenizer' in domain 'com.microsoft' in ONNX, op_version is forced to 1.\n",
      "  op_type, domain))\n"
     ]
    }
   ],
   "source": [
    "# # Convert Clustering Model into ONNX format\n",
    "seps = {TfidfVectorizer: {\"separators\": [\" \"]}}\n",
    "num_features = 1\n",
    "initial_type = [('float_input', StringTensorType([None, num_features]))]\n",
    "onx = convert_sklearn(clustering_tfidf_model,\"tfidf\", initial_types=initial_type, options=seps)\n",
    "\n",
    "\n",
    "with open(file_path_clustering_tfidf, \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce87d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert Classification_tfidf Model into ONNX format\n",
    "seps = {TfidfVectorizer: {\"separators\": [\" \"]}}\n",
    "num_features = 1\n",
    "initial_type = [('float_input', StringTensorType([None, num_features]))]\n",
    "onx = convert_sklearn(classification_tfidf_model,\"tfidf\", initial_types=initial_type, options=seps)\n",
    "\n",
    "\n",
    "with open(file_path_classification_tfidf, \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5970a798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "881697ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(300, 50), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=0, shuffle=True, solver='adam',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
      "              warm_start=False)\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
      "                     weights='uniform')\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\S\\\\S+', tokenizer=None,\n",
      "                use_idf=True, vocabulary=None)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\S\\\\S+', tokenizer=None,\n",
      "                use_idf=True, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "print_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bed9136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781530f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
